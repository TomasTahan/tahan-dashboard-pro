# Gu√≠a de Transcripci√≥n de Audio

## üé§ Flujos Soportados

El endpoint `/api/process-receipt` ahora soporta **DOS formas** de describir el gasto:

### Flujo 1: Texto Directo ‚úçÔ∏è

```json
{
  "trip_id": "uuid-del-viaje",
  "fotoUrl": "https://foto-boleta.jpg",
  "conductor_description": "Peaje de Cristo Redentor camino a Argentina"
}
```

**Proceso:**
1. Texto pasa directamente al agente IA
2. IA genera keywords basadas en imagen + texto
3. Se guarda en Supabase

### Flujo 2: Audio (Voz) üéôÔ∏è

```json
{
  "trip_id": "uuid-del-viaje",
  "fotoUrl": "https://foto-boleta.jpg",
  "audioUrl": "https://audio-grabado.webm"
}
```

**Proceso:**
1. Audio se transcribe con OpenAI Whisper
2. Transcripci√≥n ‚Üí `conductor_description`
3. Texto pasa al agente IA
4. IA genera keywords basadas en imagen + texto transcrito
5. Se guarda en Supabase con info de transcripci√≥n

## üîÑ Flujo Completo con Audio

```mermaid
graph TD
    A[Conductor graba audio] --> B[Audio se guarda en Supabase Storage]
    B --> C[POST /api/process-receipt con audioUrl]
    C --> D[OpenAI Whisper transcribe audio]
    D --> E[Texto: 'Peaje de Cristo Redentor']
    E --> F[IA analiza imagen + texto]
    F --> G[IA genera keywords]
    G --> H[Guardar en Supabase]
    H --> I{Humano confirma}
    I --> J[Crear gasto en Odoo]
```

## üìù Ejemplos de Uso

### Ejemplo 1: Con Texto

```bash
curl -X POST http://localhost:3000/api/process-receipt \
  -H "Content-Type: application/json" \
  -d '{
    "trip_id": "9667a068-5d5b-4cb7-a8b2-7068ed47782a",
    "fotoUrl": "https://supabase.co/storage/.../boleta.jpg",
    "conductor_description": "Peaje de Cristo Redentor"
  }'
```

### Ejemplo 2: Con Audio

```bash
curl -X POST http://localhost:3000/api/process-receipt \
  -H "Content-Type: application/json" \
  -d '{
    "trip_id": "9667a068-5d5b-4cb7-a8b2-7068ed47782a",
    "fotoUrl": "https://supabase.co/storage/.../boleta.jpg",
    "audioUrl": "https://supabase.co/storage/.../audio.webm"
  }'
```

### Respuesta (ambos casos):

```json
{
  "success": true,
  "message": "Receipt processed successfully",
  "data": {
    "boleta_id": "uuid",
    "estado": "espera",
    "extracted_data": {
      "descripcion": "Peaje autopista",
      "total": 15000,
      "keywords": ["peaje", "tag", "autopista", "internacional", "cristo redentor"]
    },
    "metadata": {
      "ai_keywords": ["peaje", "tag", "autopista", "internacional", "cristo redentor"],
      "conductor_description": "Peaje de Cristo Redentor",
      "audio_url": "https://...",  // Solo si vino audio
      "audio_transcribed": true,    // Solo si vino audio
      "transcription_language": "es" // Solo si vino audio
    }
  }
}
```

## ‚öôÔ∏è Configuraci√≥n de OpenAI

### Variable de Entorno

Ya est√° configurada en `.env`:

```bash
OPENAI_API_KEY="sk-proj-..."
```

### Modelo Usado

- **Whisper-1**: Modelo de transcripci√≥n de OpenAI
- Soporta m√∫ltiples formatos: webm, mp3, mp4, wav, etc.
- Detecta idioma autom√°ticamente (configurado para espa√±ol por defecto)

### L√≠mites

- **Tama√±o m√°ximo**: 25 MB por archivo
- **Duraci√≥n m√°xima**: ~2-3 minutos recomendado
- **Timeout del endpoint**: 120 segundos

## üéØ Casos de Uso

### Caso 1: Conductor Habla Mientras Maneja

```
Conductor: "Peaje... eh... Cristo Redentor, ruta a Argentina"
‚Üì
Whisper: "Peaje Cristo Redentor ruta a Argentina"
‚Üì
IA Keywords: ["peaje", "cristo redentor", "internacional", "argentina", "autopista"]
‚Üì
Categor√≠a: PEAJES INTERNACIONALES ‚úÖ
```

### Caso 2: Audio con Ruido de Fondo

```
Conductor: "Cargu√© nafta en [ruido de motor] YPF"
‚Üì
Whisper: "Cargu√© nafta en YPF" (filtra ruido)
‚Üì
IA Keywords: ["combustible", "nafta", "ypf", "gasolina"]
‚Üì
Categor√≠a: COMBUSTIBLE ‚úÖ
```

### Caso 3: Audio Corto

```
Conductor: "Peaje"
‚Üì
Whisper: "Peaje"
‚Üì
IA Keywords: ["peaje", "tag", "autopista"]
‚Üì
Categor√≠a: PEAJES (gen√©rico) ‚ö†Ô∏è (puede necesitar confirmaci√≥n)
```

## üîß Implementaci√≥n T√©cnica

### Servicio de Transcripci√≥n

**Ubicaci√≥n**: `/lib/openai/transcribe.ts`

**Funciones:**
- `transcribeAudio(audioUrl)` - Transcribe audio a texto
- `isValidAudioUrl(url)` - Valida que la URL sea segura

**Proceso:**
1. Descarga el audio desde la URL
2. Convierte a blob/buffer
3. Env√≠a a OpenAI Whisper API
4. Retorna transcripci√≥n + metadata

### Metadata Guardada

Cuando hay audio, se guarda:

```json
{
  "audio_url": "https://...",
  "audio_transcribed": true,
  "transcription": "Peaje de Cristo Redentor",
  "transcription_language": "es",
  "transcription_duration": 3.5
}
```

## üö® Manejo de Errores

### Error 1: Audio No Accesible

```json
{
  "error": "Audio transcription failed",
  "message": "Failed to fetch audio from URL: 404 Not Found",
  "boleta_id": "uuid",
  "status": "partial_success"
}
```

**Soluci√≥n**: Verificar que la URL del audio sea p√∫blica y accesible

### Error 2: Formato No Soportado

```json
{
  "error": "Audio transcription failed",
  "message": "OpenAI Whisper API error: 400 - Unsupported file format"
}
```

**Soluci√≥n**: Usar formatos soportados: webm, mp3, mp4, wav, etc.

### Error 3: Ambos Campos (Texto + Audio)

```json
{
  "error": "Invalid payload",
  "message": "No puedes enviar conductor_description y audioUrl al mismo tiempo. Elige uno."
}
```

**Soluci√≥n**: Enviar solo uno de los dos campos

## üì± Integraci√≥n con Frontend

### UI Sugerida

```jsx
function BoletaUpload({ tripId }) {
  const [fotoUrl, setFotoUrl] = useState("");
  const [inputMode, setInputMode] = useState("text"); // "text" o "audio"
  const [texto, setTexto] = useState("");
  const [audioUrl, setAudioUrl] = useState("");
  const [isRecording, setIsRecording] = useState(false);

  const handleSubmit = async () => {
    const payload = {
      trip_id: tripId,
      fotoUrl: fotoUrl,
    };

    if (inputMode === "text") {
      payload.conductor_description = texto;
    } else {
      payload.audioUrl = audioUrl;
    }

    const response = await fetch("/api/process-receipt", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload),
    });

    // ...
  };

  return (
    <div>
      <ImageUpload onChange={setFotoUrl} />

      <div>
        <button onClick={() => setInputMode("text")}>
          ‚úçÔ∏è Escribir
        </button>
        <button onClick={() => setInputMode("audio")}>
          üé§ Grabar
        </button>
      </div>

      {inputMode === "text" ? (
        <textarea
          placeholder="Describe el gasto..."
          value={texto}
          onChange={(e) => setTexto(e.target.value)}
        />
      ) : (
        <AudioRecorder
          onRecordingComplete={(url) => setAudioUrl(url)}
          isRecording={isRecording}
          setIsRecording={setIsRecording}
        />
      )}

      <button onClick={handleSubmit}>Enviar</button>
    </div>
  );
}
```

## üß™ Testing

### Test 1: Texto Directo

```bash
curl -X POST http://localhost:3000/api/process-receipt \
  -H "Content-Type: application/json" \
  -d '{
    "trip_id": "uuid",
    "fotoUrl": "https://...",
    "conductor_description": "Peaje"
  }'
```

### Test 2: Audio

```bash
# Primero, subir audio a Supabase Storage y obtener URL p√∫blica

curl -X POST http://localhost:3000/api/process-receipt \
  -H "Content-Type: application/json" \
  -d '{
    "trip_id": "uuid",
    "fotoUrl": "https://...",
    "audioUrl": "https://supabase.co/storage/.../audio.webm"
  }'
```

### Test 3: Validaci√≥n de Error (Ambos Campos)

```bash
curl -X POST http://localhost:3000/api/process-receipt \
  -H "Content-Type: application/json" \
  -d '{
    "trip_id": "uuid",
    "fotoUrl": "https://...",
    "conductor_description": "Peaje",
    "audioUrl": "https://audio.webm"
  }'

# Debe retornar error 400
```

## üí∞ Costos de OpenAI Whisper

- **Precio**: $0.006 USD por minuto de audio
- **Ejemplo**: Audio de 30 segundos = $0.003 USD
- **Estimaci√≥n mensual**: 1000 boletas con audio de 30s = $3 USD

## ‚úÖ Checklist de Implementaci√≥n

Backend:
- [x] Servicio de transcripci√≥n (`/lib/openai/transcribe.ts`)
- [x] Endpoint actualizado (`/api/process-receipt`)
- [x] Validaciones de payload
- [x] Manejo de errores
- [x] Metadata en Supabase

Frontend (pendiente):
- [ ] Componente de grabaci√≥n de audio
- [ ] Upload de audio a Supabase Storage
- [ ] UI para elegir texto vs audio
- [ ] Visualizaci√≥n de transcripci√≥n
- [ ] Manejo de estados de carga

## üìö Referencias

- [OpenAI Whisper API Docs](https://platform.openai.com/docs/guides/speech-to-text)
- Formatos soportados: webm, mp3, mp4, mpeg, mpga, m4a, wav, ogg
- L√≠mite de tama√±o: 25 MB

---

**√öltima actualizaci√≥n**: 18 de Noviembre 2025
